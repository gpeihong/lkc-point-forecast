{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fbd620-b8b9-4d4f-a3a0-dd5c2c88ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculates the error metrics in order to evaluate all casues vs casue-specific; and also with covariates vs without covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b59e8e-a530-43c7-ba77-ddffe95c8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "import patchworklib as pw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f9f4d-d75c-4d10-8027-86238b8fd7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from epiweeks import Week, Year\n",
    "from datetime import date\n",
    "def create_epiweek(date):\n",
    "    return Week.fromdate(date)\n",
    "def create_epiweekplot(epiweek):\n",
    "    epiweek = str(epiweek)\n",
    "    return F'Y{epiweek[:4]}W{epiweek[4:]}'\n",
    "def create_epiweek_fromstr(str):\n",
    "    return Week.fromstring(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c041e6",
   "metadata": {},
   "source": [
    "## For analysis of all causes versus adding up cause-specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the pred_add dataset\n",
    "def add_up(filename, target_variables, pred_add_directory):\n",
    "\n",
    "    result_df = None\n",
    "    for target_var in target_variables:\n",
    "        pred_file = os.path.join(target_var, 'pred', filename)\n",
    "        if os.path.isfile(pred_file):\n",
    "            y_pred = pd.read_csv(pred_file, parse_dates = [0], dayfirst = True, encoding='utf-8')\n",
    "            y_pred['epiweek'] = y_pred['epiweek'].apply(create_epiweek_fromstr)\n",
    "            y_pred = y_pred.set_index('epiweek')\n",
    "            y_pred = y_pred[[target_var, 'ridge', 'lasso', 'alasso', 'sgl', 'elasticnet', 'aenet', 'randomforest', 'knn', 'xgboost', 'lightgbm']]\n",
    "            y_pred.rename(columns={target_var: 'all causes'}, inplace=True)        \n",
    "            # Add y_pred to the result_df\n",
    "            if result_df is None:\n",
    "                result_df = y_pred  # Initialize with the first DataFrame\n",
    "            else:\n",
    "                result_df += y_pred \n",
    "    \n",
    "    output_file = os.path.join(pred_add_directory, filename)\n",
    "    result_df.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8633b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variables = []\n",
    "with open('target_variables.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove linebreak which is the last character of the string\n",
    "        target_variable = line[:-1]\n",
    "        # Add item to the list\n",
    "        target_variables.append(target_variable)\n",
    "print(target_variables)\n",
    "\n",
    "pred_add_directory = os.path.join('all causes', 'pred_add')\n",
    "if not os.path.exists(pred_add_directory):\n",
    "    os.makedirs(pred_add_directory)\n",
    "    \n",
    "filenames = []\n",
    "for i in range(1, 13):\n",
    "    filenames.append(f'L8_S{i}.csv')\n",
    "\n",
    "\n",
    "\n",
    "Parallel(n_jobs=12, verbose=51)(delayed(add_up)(filename, target_variables, pred_add_directory) for filename in filenames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d704cd",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d08ba-3aa0-4c53-8c6e-19aa7c2d8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_error_metrics(dataset, train_naive, target_var):\n",
    "    pred = dataset.copy()\n",
    "    model_list = list(pred.columns.values)\n",
    "    y = pred[[target_var]]\n",
    "    model_list.remove(target_var)\n",
    "    \n",
    "    # for MASE\n",
    "    pred_train_naive = train_naive.copy()\n",
    "    y_train_naive_val = pred_train_naive[[target_var]]\n",
    "    naive_train_naive_val = pred_train_naive[['naive_for_mase']]\n",
    "    \n",
    "    ##\n",
    "    error_df = pd.DataFrame()\n",
    "    #print(model_list)\n",
    "\n",
    "    for model in model_list:\n",
    "        model_val = pred[[model]].dropna()\n",
    "        window_start = model_val.index[0]\n",
    "        window_end = model_val.index[-1]\n",
    "        y_val = y.loc[window_start:window_end].copy()\n",
    "\n",
    "        error_df.at[model, 'MSE'] = mean_squared_error(y_val, model_val)\n",
    "        error_df.at[model, 'MAPE'] = mean_absolute_percentage_error(y_val, model_val)\n",
    "        error_df.at[model, 'MAE'] = mean_absolute_error(y_val, model_val)\n",
    "\n",
    "        ## MASE: scale MAE to MAE of Naive Forecast (naive forecast window matched to model window)\n",
    "        error_df.at[model, 'MASE'] = mean_absolute_error(y_val, model_val)/mean_absolute_error(y_train_naive_val, naive_train_naive_val)\n",
    "\n",
    "    return error_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d512ac0-8694-479e-b44d-37c18e404c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_error_metrics(target_var, pred_directory, pred_1_directory, pred_add_directory, pred_train_naive_directory):\n",
    "    pred_dir = os.path.join(target_var, pred_directory)\n",
    "    pred_1_dir = os.path.join(target_var, pred_1_directory)\n",
    "    pred_add_dir = os.path.join(target_var, pred_add_directory)\n",
    "    pred_train_naive_dir = os.path.join(target_var, pred_train_naive_directory)\n",
    "#     print(pred_dir)\n",
    "    for filename in os.listdir(pred_dir):\n",
    "        print(filename)\n",
    "        pred_file = os.path.join(pred_dir, filename)\n",
    "        pred_1_file = os.path.join(pred_1_dir, filename)\n",
    "        pred_add_file = os.path.join(pred_add_dir, filename)\n",
    "        pred_train_naive_file = os.path.join(pred_train_naive_dir, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(pred_file):\n",
    "            #print(pred_file)\n",
    "            y_pred = pd.read_csv(pred_file, parse_dates = [0], dayfirst = True)\n",
    "            y_pred['epiweek'] = y_pred['epiweek'].apply(create_epiweek_fromstr)\n",
    "            y_pred = y_pred.set_index('epiweek')\n",
    "            \n",
    "            y_pred_1 = pd.read_csv(pred_1_file, parse_dates = [0], dayfirst = True)\n",
    "            y_pred_1['epiweek'] = y_pred_1['epiweek'].apply(create_epiweek_fromstr)\n",
    "            y_pred_1 = y_pred_1.set_index('epiweek')\n",
    "            \n",
    "            y_pred_add = pd.read_csv(pred_add_file, parse_dates = [0], dayfirst = True)\n",
    "            y_pred_add['epiweek'] = y_pred_add['epiweek'].apply(create_epiweek_fromstr)\n",
    "            y_pred_add = y_pred_add.set_index('epiweek')\n",
    "            \n",
    "            y_pred_train_naive = pd.read_csv(pred_train_naive_file, parse_dates = [0], dayfirst = True)\n",
    "            y_pred_train_naive['epiweek'] = y_pred_train_naive['epiweek'].apply(create_epiweek_fromstr)\n",
    "            y_pred_train_naive = y_pred_train_naive.set_index('epiweek')\n",
    "\n",
    "\n",
    "            error_df = generate_error_metrics(y_pred, y_pred_train_naive, target_var)\n",
    "            error_df_1 = generate_error_metrics(y_pred_1, y_pred_train_naive, target_var)\n",
    "            error_df_add = generate_error_metrics(y_pred_add, y_pred_train_naive, target_var)\n",
    "\n",
    "            error_metrics_path = os.path.join(target_var, 'error_metrics')\n",
    "            error_metrics_1_path = os.path.join(target_var, 'error_metrics_1')\n",
    "            error_metrics_add_path = os.path.join(target_var, 'error_metrics_add')\n",
    "            if not os.path.exists(error_metrics_path):\n",
    "                os.makedirs(error_metrics_path)\n",
    "            if not os.path.exists(error_metrics_1_path ):\n",
    "                os.makedirs(error_metrics_1_path)\n",
    "            if not os.path.exists(error_metrics_add_path ):\n",
    "                os.makedirs(error_metrics_add_path)\n",
    "            error_df.to_csv(os.path.join(error_metrics_path, filename))\n",
    "            error_df_1.to_csv(os.path.join(error_metrics_1_path, filename))\n",
    "            error_df_add.to_csv(os.path.join(error_metrics_add_path, filename))\n",
    "\n",
    "\n",
    "            #print(error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a0916-8c33-4078-9d6f-295ffa700aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_error_metrics('all causes', 'pred', 'pred_1', 'pred_add', 'pred_train_naive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599cbd1",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a9ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_error_df(target_var, error_metric_directory, error_metric):\n",
    "    directory = os.path.join(target_var, error_metric_directory)\n",
    "    error_df = pd.DataFrame()\n",
    "    for step in range(1,13):\n",
    "        error_file_path = os.path.join(directory, F'L8_S{step}.csv')\n",
    "        #print(pd.read_csv(error_file_path, index_col=0))\n",
    "\n",
    "        if os.path.isfile(error_file_path):\n",
    "            error_df = pd.concat([error_df, pd.read_csv(error_file_path, index_col=0)[error_metric]], axis=1)\n",
    "    error_df.columns = range(1,13)\n",
    "    #return error_df.transpose().drop('knn', axis=1)\n",
    "    return error_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbd8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_picker(min_model_name):\n",
    "    color_dict = {\n",
    "        'ridge': mpl.colors.to_hex(mpl.cm.nipy_spectral(0.4)),\n",
    "        'lasso': mpl.colors.to_hex(mpl.cm.nipy_spectral(0.45)),\n",
    "        'alasso': mpl.colors.to_hex(mpl.cm.nipy_spectral(0.5)),\n",
    "        'sgl': mpl.colors.to_hex(mpl.cm.nipy_spectral(0.55)),\n",
    "        'elasticnet': mpl.colors.to_hex(mpl.cm.nipy_spectral(0.6)),\n",
    "        'aenet': mpl.colors.to_hex(mpl.cm.nipy_spectral(0.65)),\n",
    "        'randomforest': mpl.colors.to_hex(mpl.cm.nipy_spectral(0.75)),\n",
    "        'knn': mpl.colors.to_hex(mpl.cm.nipy_spectral(0.8)),\n",
    "        'xgboost': mpl.colors.to_hex(mpl.cm.nipy_spectral(0.85)),\n",
    "        'lightgbm': mpl.colors.to_hex(mpl.cm.nipy_spectral(0.95))\n",
    "    }\n",
    "    return color_dict[min_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5455aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marker_picker(model):\n",
    "    marker_dict = {'ridge':'d',\n",
    "                   'lasso':'<',\n",
    "                   'alasso':'>',\n",
    "                   'sgl':'x',\n",
    "                   'elasticnet':'+',\n",
    "                   'aenet':'p',\n",
    "                   'randomforest':'h', \n",
    "                   'knn':'H',\n",
    "                   'xgboost':'2',\n",
    "                   'lightgbm':'3',\n",
    "                   }\n",
    "    return marker_dict[model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc921a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_disease(str):\n",
    "    disease_dict = {\n",
    "        'Factors influencing health status and contact with health services':'Health factors',\n",
    "        'Cardiovascular disease':'Cardiovascular',\n",
    "        'Chronic respiratory disease':'Chronic respiratory',\n",
    "        'Digestive disease':'Digestive',\n",
    "        'Endocrine disorders':'Endocrine',\n",
    "        'Genitourinary disorders':'Genitourinary',\n",
    "        'Infectious and Parasitic Diseases':'Infectious & Parasitic',\n",
    "        'Musculoskeletal disease':'Musculoskeletal',\n",
    "        'Neurological and sense disorders':'Neurological & Sense',\n",
    "        'Oral diseases':'Oral',\n",
    "        'Respiratory Infection':'Respiratory',\n",
    "        'Skin diseases':'Skin',\n",
    "        'Ill-defined injuries/accidents':'Other Injuries',\n",
    "        'Ill-defined diseases':'Other Diseases'\n",
    "    }\n",
    "\n",
    "    if str in disease_dict:\n",
    "        return disease_dict[str]\n",
    "    else:\n",
    "        return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da87f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To change the name of models in the labels of the plots\n",
    "all_models = {}\n",
    "all_models['ridge'] = 'Ridge'\n",
    "all_models['lasso'] = 'LASSO'\n",
    "all_models['alasso'] = 'ALASSO'\n",
    "all_models['sgl'] = 'SGL'\n",
    "all_models['elasticnet'] = 'ENET'\n",
    "all_models['aenet'] = 'AENET'\n",
    "all_models['randomforest'] = 'RF'\n",
    "all_models['knn'] = 'KNN'\n",
    "all_models['xgboost'] = 'XGBoost'\n",
    "all_models['lightgbm'] = 'lightGBM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ed4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_disease(target_variables_file, error_metric_directory, error_metric, output_directory):\n",
    "    labs = ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'D16']\n",
    "    disease_list = []\n",
    "    with open(target_variables_file, 'r') as file:\n",
    "        for line in file:\n",
    "            # Remove linebreak which is the last character of the string\n",
    "            target_variable = line[:-1]\n",
    "            # Add item to the list\n",
    "            disease_list.append(target_variable)\n",
    "            \n",
    "    fig, axs = plt.subplots(4, 4, figsize=(20, 20))\n",
    "    fig.tight_layout(pad=5.0)\n",
    "    \n",
    "    for i, disease in enumerate(disease_list): \n",
    "        row, col = divmod(i, 4)\n",
    "        ax = axs[row, col]\n",
    "        \n",
    "        error_df = create_error_df(disease, error_metric_directory, error_metric)\n",
    "        if error_metric == 'MAPE':\n",
    "            error_df = error_df * 100\n",
    "\n",
    "        legend_handles = []\n",
    "        \n",
    "        for model in error_df.columns.values[np.r_[5:11, 12:16]]:   \n",
    "            color = color_picker(model)\n",
    "            marker = marker_picker(model)\n",
    "\n",
    "            line, = ax.plot(error_df.index.values, error_df[model], linestyle='-', linewidth=3, color=color)\n",
    "            scatter = ax.scatter(error_df.index.values, error_df[model], marker=marker, s=75, color=color)\n",
    "            # Create a legend handle combining line and scatter\n",
    "            legend_handle = mpl.lines.Line2D([], [], color=line.get_color(), marker=marker, linestyle=line.get_linestyle(), markersize=10, linewidth=3)\n",
    "            legend_handles.append((legend_handle, all_models.get(model, model)))\n",
    "            \n",
    "        ax.set_title(f'{labs[i]}: {rename_disease(disease)}', fontsize=24)\n",
    "        if row == 3:\n",
    "            ax.set_xlabel('Forecast horizon', fontsize=22)\n",
    "            x_ticks = np.arange(1, len(error_df.index.values)+1)  # Assuming error_df.index.values are numerical\n",
    "            ax.set_xticks(x_ticks)\n",
    "            ax.set_xticklabels(error_df.index.values)\n",
    "        else:\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_xticks([])\n",
    "            \n",
    "        if col == 0:\n",
    "            ax.set_ylabel(error_metric, fontsize=22)\n",
    "            \n",
    "#         if row == 0 and col == 0:\n",
    "#             handles, labels = zip(*legend_handles)\n",
    "#             ax.legend(handles, labels, bbox_to_anchor=(-0.25, 1.1), loc=0, borderaxespad=0, fontsize=24)\n",
    "            \n",
    "        ax.tick_params(axis='both', labelsize=19) \n",
    "    \n",
    "\n",
    "    plt.savefig(os.path.join(output_directory, 'casue_specific_MASE.pdf'))\n",
    "    \n",
    "        \n",
    "plot_by_disease('selected_variables.txt', 'error_metrics', 'MASE', 'all causes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc42b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_causes(target_var, error_metric_directory, error_metric_1_directory, error_metric_add_directory, error_metric, output_directory):\n",
    "    labs = ['A', 'B', 'C']\n",
    "            \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
    "    fig.tight_layout(pad=5.0)\n",
    "\n",
    "    error_df = create_error_df(target_var, error_metric_directory, error_metric)\n",
    "    error_df_1 = create_error_df(target_var, error_metric_1_directory, error_metric)\n",
    "    error_df_add = create_error_df(target_var, error_metric_add_directory, error_metric)\n",
    "    error_list = [error_df_1, error_df, error_df_add]\n",
    "    \n",
    "    titles = {}\n",
    "    title_list = ['All causes (no exogenous covariates)', 'All causes', 'Adding up cause-specific forecasts']\n",
    "    for i, (ax, error_df) in enumerate(zip(axs, error_list)): \n",
    "        \n",
    "        if error_metric == 'MAPE':\n",
    "            error_df = error_df * 100\n",
    "\n",
    "        legend_handles = []\n",
    "        \n",
    "        for model in error_df.columns.values[np.r_[0:10]]:   \n",
    "            color = color_picker(model)\n",
    "            marker = marker_picker(model)\n",
    "\n",
    "            line, = ax.plot(error_df.index.values, error_df[model], linestyle='-', linewidth=3, color=color)\n",
    "            scatter = ax.scatter(error_df.index.values, error_df[model], marker=marker, s=75, color=color)\n",
    "            # Create a legend handle combining line and scatter\n",
    "            legend_handle = mpl.lines.Line2D([], [], color=line.get_color(), marker=marker, linestyle=line.get_linestyle(), markersize=10, linewidth=3)\n",
    "            legend_handles.append((legend_handle, all_models.get(model, model)))\n",
    "            \n",
    "        ax.set_title(f'{labs[i]}: {title_list[i]}', fontsize=24)\n",
    "        \n",
    "        ax.set_xlabel('Forecast horizon', fontsize=22)\n",
    "        x_ticks = np.arange(1, len(error_df.index.values)+1)  # Assuming error_df.index.values are numerical\n",
    "        ax.set_xticks(x_ticks)\n",
    "        ax.set_xticklabels(error_df.index.values)\n",
    "            \n",
    "        if i == 0:\n",
    "            ax.set_ylabel(error_metric, fontsize=22)\n",
    "\n",
    "        if i == 0:\n",
    "            handles, labels = zip(*legend_handles)\n",
    "            ax.legend(handles, labels, bbox_to_anchor=(-0.15, 1.3), loc=0, borderaxespad=0, fontsize=24, frameon=False, handlelength=1)\n",
    "            \n",
    "        ax.tick_params(axis='both', labelsize=19) \n",
    "    \n",
    "    plt.savefig(os.path.join(output_directory, 'all_causes_MASE.pdf'), bbox_inches='tight')\n",
    "    \n",
    "\n",
    "plot_all_causes('all causes', 'error_metrics', 'error_metrics_1', 'error_metrics_add', 'MASE', 'all causes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6dfbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
