{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865fe451-64f7-46ca-a781-3bb937ef5663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#04 Simple Forecast Combination\n",
    "## This code takes the forecasts from 03IndividualModels and creates forecast combinations\n",
    "## namely Mean, Median, Expanding Weighted Mean, and Rolling Weighted Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571790ba-f510-4d64-8642-4277bc6793da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd3ce67-6f24-4020-9659-63d4087f8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "## same as in 03Autoregression, this creates epiweeks from the dates\n",
    "from epiweeks import Week, Year\n",
    "from datetime import date\n",
    "def create_epiweek(date):\n",
    "    return Week.fromdate(date)\n",
    "def create_epiweekplot(epiweek):\n",
    "    epiweek = str(epiweek)\n",
    "    return F'Y{epiweek[:4]}W{epiweek[4:]}'\n",
    "def create_epiweek_fromstr(str):\n",
    "    return Week.fromstring(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963202ba-03b3-4bab-9f46-2ccbc85dbd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for generating weights\n",
    "\n",
    "def min_max_norm_vector(x: pd.Series):\n",
    "    if not isinstance(x, pd.Series):\n",
    "        x = pd.Series(x)\n",
    "    scaler = MinMaxScaler()\n",
    "    w0 = scaler.fit_transform(x.values.reshape(-1, 1)).flatten()\n",
    "    w0 = pd.Series(w0, index = x.index)\n",
    "    return w0\n",
    "\n",
    "def proportion(x):\n",
    "    \"\"\" Proportion of sum\n",
    "    \"\"\"\n",
    "    return x / np.sum(x)\n",
    "    \n",
    "def normalize_and_proportion(x):\n",
    "    \"\"\" Min max normalization followed by proportion\n",
    "    \"\"\"\n",
    "    return proportion(min_max_norm_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69140add-604a-4b9f-ae17-3c195eb1ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weighted Mean using Bates and granger (P4) eXpanding MSE\n",
    "\n",
    "## Generate xmse\n",
    "def generate_xmse(dataset, target_var):\n",
    "    y_pred = dataset.copy()\n",
    "    y_xmse = y_pred[[target_var]].copy().drop(target_var, axis=1)\n",
    "    window_end = y_xmse.index[0]\n",
    "    df_end = y_xmse.index[-1]\n",
    "    model_list = list(y_pred.loc[:, y_pred.columns != target_var].columns.values)\n",
    "    while window_end != df_end + 1:\n",
    "        y_pred_xmse = y_pred.loc[:window_end]\n",
    "        for model in model_list:\n",
    "            y_xmse.at[window_end,model+'_xmse'] = mean_squared_error(y_pred_xmse[[target_var]], y_pred_xmse[[model]])    \n",
    "        window_end += 1\n",
    "    return y_xmse.dropna().apply(func = lambda x: normalize_and_proportion(-x), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb69bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weighted Mean using Bates and granger (P3) current time\n",
    "\n",
    "## Generate mse\n",
    "def generate_mse(dataset, target_var):\n",
    "    y_pred = dataset.copy()\n",
    "    y_mse = y_pred[[target_var]].copy().drop(target_var, axis=1)\n",
    "    window_end = y_mse.index[0]\n",
    "    df_end = y_mse.index[-1]\n",
    "    model_list = list(y_pred.loc[:, y_pred.columns != target_var].columns.values)\n",
    "    while window_end != df_end + 1:\n",
    "        y_pred_mse = y_pred.loc[window_end]\n",
    "        for model in model_list:\n",
    "            y_mse.at[window_end,model+'_mse'] = mean_squared_error(y_pred_mse[[target_var]], y_pred_mse[[model]])    \n",
    "        window_end += 1\n",
    "    \n",
    "    return y_mse.dropna().apply(func = lambda x: normalize_and_proportion(-x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd11f1ed-d882-48e6-9aa6-0c05780e35ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate combination (P1: Mean, P2: Median, P3: XMSE, P4: BG) \n",
    "def generate_pred_combi(dataset, target_var, y_xmse, y_mse):\n",
    "    y_pred = dataset.copy()\n",
    "    y_val = y_pred[[target_var]].copy()\n",
    "    y_pred_combi = y_pred[[target_var]].copy().drop(target_var, axis=1)\n",
    "    y_pred_combi['mean'] = y_pred.loc[:, y_pred.columns != target_var].mean(numeric_only = True, axis = 1)\n",
    "    y_pred_combi['median'] = y_pred.loc[:, y_pred.columns != target_var].median(numeric_only = True, axis = 1)\n",
    "    for epiweek in y_xmse.index:\n",
    "        y_pred_combi.at[epiweek, 'mean_xmse'] = np.average(y_pred.loc[epiweek, y_pred.columns != target_var], weights = y_xmse.loc[epiweek])\n",
    "    for epiweek in y_mse.index:\n",
    "        y_pred_combi.at[epiweek, 'mean_BG'] = np.average(y_pred.loc[epiweek, y_pred.columns != target_var], weights = y_mse.loc[epiweek])\n",
    "    \n",
    "    return pd.concat([y_val, y_pred_combi], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd9836-97b3-4dba-8331-9570a83d3478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_forecast_combi(dataset, target_var, filename, xmse_weights_directory, BG_weights_directory):\n",
    "    xmse_weights_directory_path = os.path.join(target_var, xmse_weights_directory)\n",
    "    BG_weights_directory_path = os.path.join(target_var, BG_weights_directory)\n",
    "    if not os.path.exists(xmse_weights_directory_path):\n",
    "        os.makedirs(xmse_weights_directory_path)\n",
    "    if not os.path.exists(BG_weights_directory_path):\n",
    "        os.makedirs(BG_weights_directory_path)\n",
    "        \n",
    "    xmse_file = os.path.join(xmse_weights_directory_path, filename)\n",
    "    BG_file = os.path.join(BG_weights_directory_path, filename)\n",
    "    y_xmse = generate_xmse(dataset, target_var)\n",
    "    y_mse = generate_mse(dataset, target_var)\n",
    "    y_xmse.to_csv(xmse_file)\n",
    "    y_mse.to_csv(BG_file)\n",
    "    return generate_pred_combi(dataset, target_var, y_xmse, y_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c29fae-0d89-4414-9e97-0d5396ef8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function finds the forecast prediction files from 03Autogression,\n",
    "## and then creates prediction forecast combination outputs\n",
    "\n",
    "def forecast_combination(target_var, pred_directory, xmse_weights_directory, BG_weights_directory):\n",
    "    directory = os.path.join(target_var, pred_directory)\n",
    "    for filename in os.listdir(directory):\n",
    "        pred_file = os.path.join(directory, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(pred_file):\n",
    "            print(pred_file)\n",
    "            \n",
    "            y_pred = pd.read_csv(pred_file, parse_dates = [0], dayfirst = True, encoding='utf-8')\n",
    "            y_pred['epiweek'] = y_pred['epiweek'].apply(create_epiweek_fromstr)\n",
    "            y_pred = y_pred.set_index('epiweek')\n",
    "\n",
    "            y_pred_combi = generate_forecast_combi(y_pred, target_var, filename, xmse_weights_directory, BG_weights_directory)\n",
    "            pred_combi_path = os.path.join(target_var, 'pred_combi')\n",
    "            if not os.path.exists(pred_combi_path):\n",
    "                os.makedirs(pred_combi_path)\n",
    "            y_pred_combi.to_csv(os.path.join(pred_combi_path, filename))\n",
    "\n",
    "            print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df613de-075e-4922-8e54-8ad31e68bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_forecast_combination(target_variables_file, pred_directory, xmse_weights_directory, BG_weights_directory):\n",
    "    target_variables = []\n",
    "    with open(target_variables_file, 'r') as file:\n",
    "        for line in file:\n",
    "            # Remove linebreak which is the last character of the string\n",
    "            target_variable = line[:-1]\n",
    "            # Add item to the list\n",
    "            target_variables.append(target_variable)\n",
    "    print(target_variables)\n",
    "\n",
    "    for target_var in target_variables:\n",
    "        forecast_combination(target_var, pred_directory, xmse_weights_directory, BG_weights_directory)\n",
    "    \n",
    "full_forecast_combination('target_variables.txt', 'pred', 'xmse_weights', 'BG_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfad8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
